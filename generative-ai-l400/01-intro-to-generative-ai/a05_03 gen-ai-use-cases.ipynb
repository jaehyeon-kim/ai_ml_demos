{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "88f6c65d",
      "metadata": {},
      "source": [
        "## Common Generative AI Use Cases\n",
        "\n",
        "In this lab, you will implement several common generative AI use cases.\n",
        "\n",
        "In addition to being the most common types of generative AI applications, these techniques serve as the building blocks of many more complex applications.\n",
        "\n",
        "## Objective\n",
        "\n",
        "You will learn to use text prompting for the following tasks:\n",
        "\n",
        "- Ideation\n",
        "- Text Classification\n",
        "- Text Summarization\n",
        "- Text Extraction\n",
        "- Question Answering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3gTencajJnXM",
      "metadata": {
        "id": "3gTencajJnXM"
      },
      "source": [
        "## Task 1. Initialize Vertex AI in a Colab Enterprise notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "YNiOOvaiTdnEJxDdiqMVRjrt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 17621,
          "status": "ok",
          "timestamp": 1735202716574,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "YNiOOvaiTdnEJxDdiqMVRjrt",
        "outputId": "c9f93fa6-c79a-4c55-a09f-4fceb6cd178d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m6.3/6.9 MB\u001b[0m \u001b[31m189.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "GVTumYLOJR8V",
      "metadata": {
        "executionInfo": {
          "elapsed": 4038,
          "status": "ok",
          "timestamp": 1735202801649,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "GVTumYLOJR8V"
      },
      "outputs": [],
      "source": [
        "from inspect import cleandoc\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "-vJQz1uxJcnJ",
      "metadata": {
        "executionInfo": {
          "elapsed": 2365,
          "status": "ok",
          "timestamp": 1735202831067,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "-vJQz1uxJcnJ"
      },
      "outputs": [],
      "source": [
        "PROJECT = !gcloud config get-value project\n",
        "PROJECT_ID = PROJECT[0]\n",
        "REGION = \"us-east4\"\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QvZecBDsJ8iz",
      "metadata": {
        "id": "QvZecBDsJ8iz"
      },
      "source": [
        "## Task 2. Load a generative model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "knO2NpYsJ4J7",
      "metadata": {
        "executionInfo": {
          "elapsed": 1405,
          "status": "ok",
          "timestamp": 1735202962385,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "knO2NpYsJ4J7"
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\"gemini-pro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ahDt7DQ6KD4j",
      "metadata": {
        "id": "ahDt7DQ6KD4j"
      },
      "source": [
        "## Task 3. Ideation\n",
        "\n",
        "Within the context of using a generative AI model, \"ideation\" means using the model to help you brainstorm new content: article titles, sections to include in a document, interview questions, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "CveoQi7iKNCM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5824,
          "status": "ok",
          "timestamp": 1735203055254,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "CveoQi7iKNCM",
        "outputId": "b3568524-5683-46a2-f02e-1ed85fe65dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Strategies for Overcoming Writer's Block:\n",
            "\n",
            "**1. Break Down the Task:**\n",
            "\n",
            "* **Divide your writing into smaller, more manageable chunks.** Instead of staring at a blank page and feeling overwhelmed, focus on completing one section at a time. This can help you make progress and build momentum.\n",
            "* **Set realistic goals.** Don't try to write a perfect first draft. Aim for a rough draft that you can revise and improve later.\n",
            "\n",
            "**2. Prime the Pump:**\n",
            "\n",
            "* **Freewriting:** Write continuously for a set amount of time, without worrying about grammar, spelling, or making sense. This can help you get your creative juices flowing and overcome the initial hurdle of starting.\n",
            "* **Brainstorming:** Generate ideas by listing everything that comes to mind about your topic. Don't censor yourself; just write down whatever ideas come to you.\n",
            "* **Reading:** Immerse yourself in the work of other writers. Pay attention to their style, structure, and use of language. This can inspire you and give you new ideas.\n",
            "\n",
            "**3. Change Your Environment:**\n",
            "\n",
            "* **Work in a different location.** Go to a coffee shop, library, or park. A change of scenery can help you see things from a fresh perspective.\n",
            "* **Listen to music.** Choose music that is calming and inspiring to you. This can help you relax and focus.\n",
            "* **Take a break.** Sometimes the best way to overcome writer's block is to step away from your work for a while. Go for a walk, take a nap, or do something else that you enjoy.\n",
            "\n",
            "**4. Seek Support:**\n",
            "\n",
            "* **Talk to a friend, family member, or therapist about your writing goals and challenges.** They can offer support and encouragement.\n",
            "* **Join a writing group or online forum.** This can be a great way to connect with other writers, share your work, and get feedback.\n",
            "\n",
            "**5. Consider the Underlying Cause:**\n",
            "\n",
            "* **Is there a specific reason why you're feeling blocked?** Are you feeling stressed, anxious, or uninspired? Addressing the underlying cause of your writer's block can help you overcome it more effectively.\n",
            "* **Sometimes, writer's block can be a sign of burnout.** If you've been pushing yourself too hard, it's important to take a break and recharge.\n",
            "\n",
            "**Additional Tips:**\n",
            "\n",
            "* **Visualize your success.** Imagine yourself completing your writing project and feeling proud of your accomplishment.\n",
            "* **Reward yourself for your progress.** This will help you stay motivated and on track.\n",
            "* **Don't be afraid to experiment.** Try different writing exercises and techniques to find what works best for you.\n",
            "* **Most importantly, be patient with yourself.** Writer's block is a normal part of the writing process. Don't give up!\n",
            "\n",
            "I hope these strategies help you overcome writer's block and get back to writing!\n"
          ]
        }
      ],
      "source": [
        "# This is a case where you may want the model to be more creative or surprising in the content it generates.\n",
        "# To enable that, create a GenerationConfig object by copying the code below to a new code cell and running it:\n",
        "creative_gen_config = GenerationConfig(temperature=1, top_p=0.8)\n",
        "\n",
        "prompt = \"What are some strategies for overcoming writer's block?\"\n",
        "\n",
        "response = model.generate_content(prompt, generation_config=creative_gen_config)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "HUTSPfuyKfyM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4772,
          "status": "ok",
          "timestamp": 1735203115143,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "HUTSPfuyKfyM",
        "outputId": "c2426d0f-002b-402c-b9f3-18cd638f9d14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## 10 Interview Questions for Prompt Engineering\n",
            "\n",
            "**1. Describe your understanding of the role of a prompt engineer.**\n",
            "**2. What are the key differences between a prompt engineer and a machine learning engineer?**\n",
            "**3. What are some of the challenges you've faced while working as a prompt engineer? How did you overcome them?**\n",
            "**4. Explain the iterative process of prompt engineering. How do you know when a prompt is successful?**\n",
            "**5. Discuss the importance of understanding different NLP models and their capabilities when designing prompts.**\n",
            "**6. How do you ensure your prompts are unbiased and do not perpetuate harmful stereotypes?**\n",
            "**7. What are some of the tools and techniques you use to evaluate the effectiveness of your prompts?**\n",
            "**8. Describe a project where you used prompt engineering to achieve a specific goal. What were the results?**\n",
            "**9. How do you stay up-to-date with the latest advancements in the field of prompt engineering?**\n",
            "**10. What are some of the ethical considerations that prompt engineers should be aware of?**\n",
            "\n",
            "**Bonus Questions:**\n",
            "\n",
            "* Can you provide an example of a prompt you designed that was particularly successful?\n",
            "* What are your thoughts on the future of prompt engineering?\n",
            "* Do you have any experience with using large language models like me for prompt engineering?\n",
            "\n",
            "These questions assess the candidate's knowledge of prompt engineering, their problem-solving skills, and their ability to think critically about the ethical implications of their work. Be sure to tailor the questions to your specific needs and the experience level of the candidate.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Provide ten interview questions for the role of prompt engineer.\"\n",
        "\n",
        "response = model.generate_content(prompt, generation_config=creative_gen_config)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccu1DlFYKrys",
      "metadata": {
        "id": "ccu1DlFYKrys"
      },
      "source": [
        "## Task 4. Text Classification\n",
        "\n",
        "In modern enterprises, a lot of work is dedicated to putting the right information in the right place. Routing customer support emails to the correct team or sending customer reviews to the relevant department are two examples. To do this, you could ask generative AI to classify those blocks of text to determine the right team.\n",
        "\n",
        "Classification can have many possible applications, including:\n",
        "\n",
        "- Sentiment analysis\n",
        "- Topic classification\n",
        "- Spam detection\n",
        "- Intent recognition\n",
        "- Language identification\n",
        "- Toxicity detection\n",
        "- Emotion detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "n7L3qAGBK77T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 873,
          "status": "ok",
          "timestamp": 1735203249226,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "n7L3qAGBK77T",
        "outputId": "40c3fcbe-0778-40c5-9e1f-7ddfcdcf6165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Intent: Making a reservation\n",
            "\n",
            "The user is requesting to book a table for two at a restaurant called Juan for May 1st. This falls under the category of \"making a reservation\". \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# For a more tightly-constrained summary, you may want to decrease the temperature and top_p parameters:\n",
        "predictable_gen_config = GenerationConfig(temperature=0.1, top_p=0.1)\n",
        "\n",
        "prompt = \"\"\"\n",
        "Given a user's input, classify their intent, such as \"finding information\", \"making a reservation\", or \"placing an order\". \\n\n",
        "user input: Hi, can you please book a table for two at Juan for May 1?\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt, generation_config=predictable_gen_config)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "henpIGF9LJoc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 889,
          "status": "ok",
          "timestamp": 1735203401639,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "henpIGF9LJoc",
        "outputId": "b1ae2fc7-6d16-430d-a7d9-8a1068eac03c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "entertainment \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# You can help guide correct classifications of your data by providing examples:\n",
        "prompt = \"\"\"\n",
        "What is the topic for a given news headline? \\n\n",
        "- business \\n\n",
        "- entertainment \\n\n",
        "- health \\n\n",
        "- sports \\n\n",
        "- technology \\n\\n\n",
        "\n",
        "Text: Pixel 7 Pro Expert Hands On Review. \\n\n",
        "The answer is: technology \\n\n",
        "\n",
        "Text: Quit smoking? \\n\n",
        "The answer is: health \\n\n",
        "\n",
        "Text: Birdies or bogeys? Top 5 tips to hit under par \\n\n",
        "The answer is: sports \\n\n",
        "\n",
        "Text: Relief from local minimum-wage hike looking more remote \\n\n",
        "The answer is: business \\n\n",
        "\n",
        "Text: You won't guess who just arrived in Bari, Italy for the movie premiere. \\n\n",
        "The answer is:\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt, generation_config=predictable_gen_config)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ofjLBlBGL9MD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "executionInfo": {
          "elapsed": 3470,
          "status": "ok",
          "timestamp": 1735203572851,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "ofjLBlBGL9MD",
        "outputId": "552ebfc9-a43e-4101-dc2c-e9dc2a825d7f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-992f9d72-3036-4ab7-aab7-0582d49ce8f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment_groundtruth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i love this product. it does have everything i...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>all i can say is that you will be happy after ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>its way too expensive and not worth the price</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am feeling okay. its neither good nor too bad.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-992f9d72-3036-4ab7-aab7-0582d49ce8f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-992f9d72-3036-4ab7-aab7-0582d49ce8f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-992f9d72-3036-4ab7-aab7-0582d49ce8f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1125595e-3da4-47ae-a7c8-164b6018c8d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1125595e-3da4-47ae-a7c8-164b6018c8d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1125595e-3da4-47ae-a7c8-164b6018c8d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              review sentiment_groundtruth\n",
              "0  i love this product. it does have everything i...              positive\n",
              "1  all i can say is that you will be happy after ...              positive\n",
              "2      its way too expensive and not worth the price              negative\n",
              "3   i am feeling okay. its neither good nor too bad.               neutral"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# One great thing about defining a task as a classification task is that you can evaluate\n",
        "# classification results very easily and meaningfully.\n",
        "\n",
        "# Run this cell to import pandas as well as a classification_report metric from sklearn.\n",
        "# You will also define some ground truth data for evaluation.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "review_data_df = pd.DataFrame(\n",
        "    {\n",
        "        \"review\": [\n",
        "            \"i love this product. it does have everything i am looking for!\",\n",
        "            \"all i can say is that you will be happy after buying this product\",\n",
        "            \"its way too expensive and not worth the price\",\n",
        "            \"i am feeling okay. its neither good nor too bad.\",\n",
        "        ],\n",
        "        \"sentiment_groundtruth\": [\"positive\", \"positive\", \"negative\", \"neutral\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "review_data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "-MyFhLjSMVyz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "executionInfo": {
          "elapsed": 2255,
          "status": "ok",
          "timestamp": 1735203675933,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "-MyFhLjSMVyz",
        "outputId": "5c9e3076-7f12-4ef6-d685-45912f58ee3b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6b2ad86b-f759-49b5-9ccf-c2e01aa97b9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment_groundtruth</th>\n",
              "      <th>sentiment_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i love this product. it does have everything i...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>all i can say is that you will be happy after ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>its way too expensive and not worth the price</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am feeling okay. its neither good nor too bad.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b2ad86b-f759-49b5-9ccf-c2e01aa97b9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b2ad86b-f759-49b5-9ccf-c2e01aa97b9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b2ad86b-f759-49b5-9ccf-c2e01aa97b9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-77569ae3-9dbb-4dab-b13c-f0bd6ec7aa81\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77569ae3-9dbb-4dab-b13c-f0bd6ec7aa81')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-77569ae3-9dbb-4dab-b13c-f0bd6ec7aa81 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              review sentiment_groundtruth  \\\n",
              "0  i love this product. it does have everything i...              positive   \n",
              "1  all i can say is that you will be happy after ...              positive   \n",
              "2      its way too expensive and not worth the price              negative   \n",
              "3   i am feeling okay. its neither good nor too bad.               neutral   \n",
              "\n",
              "  sentiment_prediction  \n",
              "0             positive  \n",
              "1             positive  \n",
              "2             negative  \n",
              "3              neutral  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now that you have the data with reviews and sentiments as ground truth labels,\n",
        "# you can call the text generation model on each review row using the apply function.\n",
        "\n",
        "# The get_sentiment function will be called to predict the sentiment for each row's review column,\n",
        "# and the results will be stored in the sentiment_prediction column.\n",
        "\n",
        "\n",
        "def get_sentiment(row):\n",
        "    prompt = f\"\"\"Classify the sentiment of the following review as \"positive\", \"neutral\" or \"negative\". Return only the classification.\n",
        "                review: {row}\n",
        "              \"\"\"\n",
        "    response = model.generate_content(\n",
        "        contents=prompt, generation_config=predictable_gen_config\n",
        "    ).text\n",
        "    return response\n",
        "\n",
        "\n",
        "review_data_df[\"sentiment_prediction\"] = review_data_df[\"review\"].apply(get_sentiment)\n",
        "review_data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "WHcJryXLM3ct",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "executionInfo": {
          "elapsed": 449,
          "status": "ok",
          "timestamp": 1735203751917,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "WHcJryXLM3ct",
        "outputId": "1bcd072f-17ea-4720-d045-37feab043810"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "              precision    recall  f1-score   support\n",
              "\n",
              "    negative       1.00      1.00      1.00         1\n",
              "     neutral       1.00      1.00      1.00         1\n",
              "    positive       1.00      1.00      1.00         2\n",
              "\n",
              "    accuracy                           1.00         4\n",
              "   macro avg       1.00      1.00      1.00         4\n",
              "weighted avg       1.00      1.00      1.00         4\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now you can call the classification_report function from sklearn to return classification metrics\n",
        "# based on comparing the sentiment_groundtruth and predicted sentiment_prediction fields:\n",
        "\n",
        "report = classification_report(\n",
        "    review_data_df[\"sentiment_groundtruth\"], review_data_df[\"sentiment_prediction\"]\n",
        ")\n",
        "Markdown(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wr8Gb9duNJe_",
      "metadata": {
        "id": "wr8Gb9duNJe_"
      },
      "source": [
        "## Task 5. Text Summarization\n",
        "\n",
        "Sometimes you want to read the entirety of a text, and sometimes you just want the gist of it. Generative AI models can help create summaries of longer texts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mK6PdN_lNfji",
      "metadata": {
        "id": "mK6PdN_lNfji"
      },
      "outputs": [],
      "source": [
        "# You may want to continue to use the more tightly-constrained temperature and top_p parameters we used above:\n",
        "predictable_gen_config = GenerationConfig(temperature=0.1, top_p=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "RqzdPU2PNsjD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1343,
          "status": "ok",
          "timestamp": 1735203973841,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "RqzdPU2PNsjD",
        "outputId": "43aaa7bc-809a-4761-a1a6-8bfc1845fac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Summary:\n",
            "\n",
            "Quantum computers are sensitive to errors, which limits their usefulness. Quantum error correction aims to solve this by encoding information across multiple qubits, creating a more stable \"logical qubit\". This will allow for larger, more powerful quantum computers capable of running complex algorithms. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Notice how this prompt's instructions to summarize also give some guidance on the length of the summary desired.\n",
        "# Run the following code block in a new code cell to generate a short summary.\n",
        "\n",
        "prompt = \"\"\"\n",
        "Provide a very short summary, no more than three sentences, for the following article:\n",
        "\n",
        "Our quantum computers work by manipulating qubits in an orchestrated fashion that we call quantum algorithms.\n",
        "The challenge is that qubits are so sensitive that even stray light can cause calculation errors — and the problem worsens as quantum computers grow.\n",
        "This has significant consequences, since the best quantum algorithms that we know for running useful applications require the error rates of our qubits to be far lower than we have today.\n",
        "To bridge this gap, we will need quantum error correction.\n",
        "Quantum error correction protects information by encoding it across multiple physical qubits to form a \"logical qubit,\" and is believed to be the only way to produce a large-scale quantum computer with error rates low enough for useful calculations.\n",
        "Instead of computing on the individual qubits themselves, we will then compute on logical qubits. By encoding larger numbers of physical qubits on our quantum processor into one logical qubit, we hope to reduce the error rates to enable useful quantum algorithms.\n",
        "\n",
        "Summary:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt, generation_config=predictable_gen_config)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "Nq9b4k8mN-r9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "executionInfo": {
          "elapsed": 2174,
          "status": "ok",
          "timestamp": 1735204030831,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "Nq9b4k8mN-r9",
        "outputId": "4de50320-199a-40bc-db81-dd641b187e8a"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Summary in four bullet points:\n",
              "\n",
              "* **Quantum computers use qubits, which are sensitive to errors.** Even small disturbances like stray light can cause mistakes in calculations.\n",
              "* **Current error rates are too high for useful applications.** The best quantum algorithms require much lower error rates than we have today.\n",
              "* **Quantum error correction is the solution.** It encodes information across multiple qubits to create a \"logical qubit\" with lower error rates.\n",
              "* **Logical qubits will enable useful quantum algorithms.** By using logical qubits, we can reduce errors and run complex calculations that are currently impossible. \n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You might prefer your summary to be delivered as bullet points, displayed using Markdown to interpret the text formatting that Gemini returns:\n",
        "\n",
        "prompt = \"\"\"\n",
        "Provide a very short summary in four bullet points for the following article:\n",
        "\n",
        "Our quantum computers work by manipulating qubits in an orchestrated fashion that we call quantum algorithms.\n",
        "The challenge is that qubits are so sensitive that even stray light can cause calculation errors — and the problem worsens as quantum computers grow.\n",
        "This has significant consequences, since the best quantum algorithms that we know for running useful applications require the error rates of our qubits to be far lower than we have today.\n",
        "To bridge this gap, we will need quantum error correction.\n",
        "Quantum error correction protects information by encoding it across multiple physical qubits to form a \"logical qubit,\" and is believed to be the only way to produce a large-scale quantum computer with error rates low enough for useful calculations.\n",
        "Instead of computing on the individual qubits themselves, we will then compute on logical qubits. By encoding larger numbers of physical qubits on our quantum processor into one logical qubit, we hope to reduce the error rates to enable useful quantum algorithms.\n",
        "\n",
        "Bullet points:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(\n",
        "    contents=prompt, generation_config=predictable_gen_config\n",
        ")\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "KDVuiZR5OKd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "executionInfo": {
          "elapsed": 1717,
          "status": "ok",
          "timestamp": 1735204128437,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "KDVuiZR5OKd3",
        "outputId": "c6b245c9-0bf1-4749-f9bc-7abdbbf1580a"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The customer received the wrong item and wanted to return it for a refund. The support agent processed the refund and the customer will receive their money back within 14 days.\n",
              "\n",
              "To-do's for the support agent:\n",
              "\n",
              "* Process the refund for the customer.\n",
              "* Send the customer an email confirmation of the refund.\n",
              "* Close the ticket."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summarization can also be done on other forms of documents, like an email thread or the transcript of a conversation:\n",
        "\n",
        "prompt = \"\"\"\n",
        "Please generate a summary of the following conversation and at the end summarize the to-do's for the support Agent:\n",
        "\n",
        "Customer: Hi, I'm Larry, and I received the wrong item.\n",
        "\n",
        "Support Agent: Hi, Larry. How would you like to see this resolved?\n",
        "\n",
        "Customer: That's alright. I want to return the item and get a refund, please.\n",
        "\n",
        "Support Agent: Of course. I can process the refund for you now. Can I have your order number, please?\n",
        "\n",
        "Customer: It's [ORDER NUMBER].\n",
        "\n",
        "Support Agent: Thank you. I've processed the refund, and you will receive your money back within 14 days.\n",
        "\n",
        "Customer: Thank you very much.\n",
        "\n",
        "Support Agent: You're welcome, Larry. Have a good day!\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(\n",
        "    contents=prompt, generation_config=predictable_gen_config\n",
        ")\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nxZXc7UpOks8",
      "metadata": {
        "id": "nxZXc7UpOks8"
      },
      "source": [
        "## Task 6. Text Extraction\n",
        "\n",
        "Text Extraction is the process of pulling structured fields from unstructured text. By unstructured text, we mean text that lacks a computer-readable structure like CSV, JSON, or YAML, even if a human can identify some structure (like in the ingredient list of a recipe).\n",
        "\n",
        "Some specific types of extraction include:\n",
        "\n",
        "- **Named entity recognition (NER)**: Extract named entities from text, including people, places, organizations, and dates.\n",
        "- **Relation extraction**: Extract the relationships between entities in text, such as family relationships between people.\n",
        "- **Event extraction**: Extract events from text, such as project milestones and product launches.\n",
        "- **Question answering**: Extract information from text to answer a question.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "hlL0OuK4O-ol",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2576,
          "status": "ok",
          "timestamp": 1735204311726,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "hlL0OuK4O-ol",
        "outputId": "913b3a74-86a5-4299-f7d8-696e82a51916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "[\n",
            "  {\n",
            "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
            "    \"cheese_selection\": \"Swiss\"\n",
            "  },\n",
            "  {\n",
            "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
            "    \"cheese_selection\": \"Swiss\"\n",
            "  },\n",
            "  {\n",
            "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
            "    \"cheese_selection\": \"Muenster\"\n",
            "  },\n",
            "  {\n",
            "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
            "    \"cheese_selection\": \"Muenster\"\n",
            "  },\n",
            "  {\n",
            "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
            "    \"cheese_selection\": \"Muenster\"\n",
            "  },\n",
            "  {\n",
            "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
            "    \"cheese_selection\": \"Cheddar\"\n",
            "  },\n",
            "  {\n",
            "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
            "    \"cheese_selection\": \"Cheddar\"\n",
            "  },\n",
            "  {\n",
            "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
            "    \"cheese_selection\": \"Cheddar\"\n",
            "  }\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "order = \"We need eight grilled cheese sandwiches. Two with swiss cheese, three with muenster, three with cheddar.\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "    Break the customer's order into individual items with keys for the following fields:\n",
        "    - item_name\n",
        "    - cheese_selection\n",
        "\n",
        "    Order:\n",
        "    {order_field}\n",
        "\"\"\".format(order_field=order)\n",
        "\n",
        "response = model.generate_content(\n",
        "    contents=prompt, generation_config=predictable_gen_config\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hV7gQZrmP1pV",
      "metadata": {
        "id": "hV7gQZrmP1pV"
      },
      "source": [
        "**Note**: Gemini's [Function Calling](https://ai.google.dev/gemini-api/tutorials/extract_structured_data#use_function_calling) has capabilities to extract parameters according to their descriptions in order to allow you to call a function. While this is outside of the scope of this lab, you may want to investigate using these capabilities for Extraction, even if your end goal isn't to call a function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_YfoGvh6P_tl",
      "metadata": {
        "id": "_YfoGvh6P_tl"
      },
      "source": [
        "## Task 7. Question Answering\n",
        "\n",
        "Answering questions is one of the most common and most impressive uses of generative AI. The information the model returns could come from patterns in data the model was trained on or from additional information you provide the model as context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "_fxqrduVQQE7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 887,
          "status": "ok",
          "timestamp": 1735204639774,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "_fxqrduVQQE7",
        "outputId": "cd51d451-a10e-4681-9036-9d4cd8395a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dwight D. Eisenhower was President of the United States in 1955. He belonged to the Republican Party.\n"
          ]
        }
      ],
      "source": [
        "# Run this code for an example of answering an Open Domain question, meaning its answer is\n",
        "# publically available on the internet and does not require very recent or up-to-date knowledge.\n",
        "# An answer that meets those qualifications may have been included in the model's training data:\n",
        "\n",
        "prompt = \"\"\"Q: Who was President of the United States in 1955?\n",
        "              Which party did he belong to?\n",
        "            A:\n",
        "        \"\"\"\n",
        "response = model.generate_content(\n",
        "    contents=prompt, generation_config=predictable_gen_config\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "DJ1BkI12Qeib",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3946,
          "status": "ok",
          "timestamp": 1735204735860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "DJ1BkI12Qeib",
        "outputId": "610b2d24-02bb-448d-bdec-a30bc6dfff92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Prompt]\n",
            "Answer the question given in the contex below:\n",
            "Context: \n",
            "Storage and content policy \n",
            "\n",
            "How durable is my data in Cloud Storage? \n",
            "\n",
            "Cloud Storage is designed for 99.999999999% (11 9's) annual durability, which is appropriate for even primary storage and\n",
            "business-critical applications. This high durability level is achieved through erasure coding that stores data pieces redundantly\n",
            "across multiple devices located in multiple availability zones.\n",
            "Objects written to Cloud Storage must be redundantly stored in at least two different availability zones before the\n",
            "write is acknowledged as successful. Checksums are stored and regularly revalidated to proactively verify that the data\n",
            "integrity of all data at rest as well as to detect corruption of data in transit. If required, corrections are automatically\n",
            "made using redundant data. Customers can optionally enable object versioning to add protection against accidental deletion.\n",
            "?\n",
            "\n",
            "Question: How is high availability achieved? \n",
            "\n",
            "Answer:\n",
            "\n",
            "[Response]\n",
            "## High Availability in Cloud Storage\n",
            "\n",
            "Cloud Storage achieves high availability through a combination of redundancy and proactive data integrity checks:\n",
            "\n",
            "**Redundancy:**\n",
            "\n",
            "* **Erasure coding:** Data is split into pieces and stored redundantly across multiple devices in different availability zones. This ensures that even if some devices fail, the data remains accessible.\n",
            "* **Object replication:** Objects are written to at least two different availability zones before the write is acknowledged as successful. This further protects against data loss in case of a zone outage.\n",
            "\n",
            "**Data Integrity Checks:**\n",
            "\n",
            "* **Checksums:** Checksums are stored for each object and regularly revalidated to detect any data corruption.\n",
            "* **Automatic correction:** If corruption is detected, Cloud Storage automatically repairs the data using the redundant copies.\n",
            "\n",
            "**Additional Features:**\n",
            "\n",
            "* **Object versioning:** This allows you to restore previous versions of an object in case of accidental deletion or modification.\n",
            "\n",
            "These measures ensure that your data is highly available and protected against data loss or corruption. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run this code for an example of answering an closed domain question, meaning its answer may be private\n",
        "# to your organization and therefore you need to provide that information to the model within the prompt's \"context\":\n",
        "\n",
        "context = \"\"\"\n",
        "Storage and content policy \\n\n",
        "How durable is my data in Cloud Storage? \\n\n",
        "Cloud Storage is designed for 99.999999999% (11 9's) annual durability, which is appropriate for even primary storage and\n",
        "business-critical applications. This high durability level is achieved through erasure coding that stores data pieces redundantly\n",
        "across multiple devices located in multiple availability zones.\n",
        "Objects written to Cloud Storage must be redundantly stored in at least two different availability zones before the\n",
        "write is acknowledged as successful. Checksums are stored and regularly revalidated to proactively verify that the data\n",
        "integrity of all data at rest as well as to detect corruption of data in transit. If required, corrections are automatically\n",
        "made using redundant data. Customers can optionally enable object versioning to add protection against accidental deletion.\n",
        "\"\"\"\n",
        "\n",
        "question = \"How is high availability achieved?\"\n",
        "\n",
        "prompt = f\"\"\"Answer the question given in the contex below:\n",
        "Context: {context}?\\n\n",
        "Question: {question} \\n\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "print(\"[Prompt]\")\n",
        "print(prompt)\n",
        "\n",
        "print(\"[Response]\")\n",
        "response = model.generate_content(\n",
        "    contents=prompt, generation_config=predictable_gen_config\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U-wGKDXAQ8hs",
      "metadata": {
        "id": "U-wGKDXAQ8hs"
      },
      "source": [
        "**Note**: Evaluating the correctness of question-answering systems can be challenging, but Vertex AI provides a [Generative AI evaluation service](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval#question-answering) with some metrics tailor-made for this use case.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33562fb7",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "- Study Gemini [Function Calling with Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling).\n",
        "- Learn more about the [Generative AI evaluation service](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval#question-answering).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "student-02-fcdf3bbc4fd9 (Dec 26, 2024, 7:41:51 PM)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
