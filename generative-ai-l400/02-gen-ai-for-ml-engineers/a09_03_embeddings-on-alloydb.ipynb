{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af79239-93b7-4c20-8649-ca0f9dace2e2",
   "metadata": {},
   "source": [
    "## Storing and Querying Embeddings with AlloyDB for PostgreSQL\n",
    "\n",
    "### Overview\n",
    "\n",
    "This lab demonstrates how to easily integrate generative AI features into your applications with just a few lines of code using pgvector, LangChain, and LLMs on Google Cloud.\n",
    "\n",
    "We will build a sample Python application together that will be able to understand and respond to human language queries about the relational data stored in your PostgreSQL database. In fact, we will further push the creative limits of the application by teaching it to generate new content based on our existing dataset.\n",
    "\n",
    "This lab utilizes an example of an e-commerce company that operates an online marketplace for buying and selling children's toys. The company aims to incorporate new generative AI experiences into its e-commerce applications for both buyers and sellers on the platform.\n",
    "\n",
    "The goals are:\n",
    "\n",
    "- **(Usecase 1) For buyers**: Build a new AI-powered hybrid search, where users can describe their needs in simple English text, along with regular filters (like price, etc.)\n",
    "- **(Usecase 2) For sellers**: Add a new AI-powered content generation feature, where sellers will get auto-generated item description suggestions for new products that they want to add to the platform.\n",
    "\n",
    "Dataset: The dataset for this lab has been sampled and created from a larger public retail dataset available at [Kaggle](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fwww.kaggle.com%2Fdatasets%2Fpromptcloud%2Fwalmart-product-details-2020). The sampled dataset used in this lab has only about 800 toy products, while the public dataset has over 370,000 products in different categories.\n",
    "\n",
    "### Objective\n",
    "\n",
    "At the end of this lab:\n",
    "\n",
    "- You will have a good understanding of how to use the [pgvector extension](https://github.com/pgvector/pgvector) to store and search vector embeddings in PostgreSQL. Learn more about [vector embeddings](https://cloud.google.com/blog/topics/developers-practitioners/meet-ais-multitool-vector-embeddings).\n",
    "- You will get a hands-on experience with using the open-source [LangChain framework](https://python.langchain.com/docs/get_started/introduction) to develop applications powered by large language models. LangChain makes it easier to develop and deploy applications against any LLM model in a vendor-agnostic manner.\n",
    "- You will learn about the powerful features in [Google PaLM models made available through Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4548210b-3f65-4626-8a83-5eff202c392f",
   "metadata": {},
   "source": [
    "### Task 1. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad337e-ea96-42dd-8409-651fb77ca73a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install numpy pandas\n",
    "!pip install pgvector\n",
    "!pip install langchain langchain_google_vertexai transformers\n",
    "!pip install google-cloud-aiplatform\n",
    "!pip install psycopg2-binary\n",
    "!pip install protobuf\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4784d8b-6023-4f43-8b14-dad6f08b9d09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef82210-4f18-4bf7-9d52-dd41a6ce2407",
   "metadata": {},
   "source": [
    "### Task 2. Download and load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b63e1f-d61a-4735-ac89-fd63f463ec9e",
   "metadata": {},
   "source": [
    "An AlloyDB cluster named cymbal-alloy-cluster is configured in this lab. To begin, let's locate the AlloyDB cluster's IP address.\n",
    "\n",
    "1. On the Google Cloud console title bar, type \"AlloyDB\" in the Search field, then click AlloyDB in the Products & Pages section.\n",
    "2. Locate the cluster named cymbal-alloy-cluster, and the primary instance named cymbal-instance. The private IP address of this instance serves as your access point for utilizing AlloyDB throughout the lab.\n",
    "\n",
    "Back in Vertex AI Workbench Notebook, import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c23d2a-9505-4429-815b-3b5af83ad387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-02-2cf3961f017f\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2dff4ba-5475-4578-a9b0-7eee6631c869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully!\n",
      "('74a695e3675efc2aad11ed73c46db29b', 'Slip N Slide Triple Racer with Slide Boogies', 'Triple Racer Slip and Slide with Boogie Boards. The unit is 16 foot long. The unit has 3 sliding lanes.', 37.21)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Replace with your AlloyDB cluster credentials\n",
    "cluster_ip_address = \"10.103.0.2\"\n",
    "database_user = \"postgres\"\n",
    "database_password = \"postgres\"\n",
    "\n",
    "# Set environment variables for psql connection\n",
    "os.environ[\"PGHOST\"] = cluster_ip_address\n",
    "os.environ[\"PGUSER\"] = database_user\n",
    "os.environ[\"PGPASSWORD\"] = database_password\n",
    "\n",
    "# Establish a connection to the database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=cluster_ip_address,\n",
    "        user=database_user,\n",
    "        password=database_password\n",
    "    )\n",
    "    print(\"Connected to the database successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection error:\", e)\n",
    "exit(1)\n",
    "\n",
    "# Read the dataset from the URL\n",
    "DATASET_URL = \"https://github.com/GoogleCloudPlatform/python-docs-samples/raw/main/cloud-sql/postgres/pgvector/data/retail_toy_dataset.csv\"\n",
    "df = pd.read_csv(DATASET_URL)\n",
    "\n",
    "# Select desired columns and drop missing values\n",
    "df = df.loc[:, [\"product_id\", \"product_name\", \"description\", \"list_price\"]]\n",
    "df = df.dropna()\n",
    "\n",
    "# Save the DataFrame to the AlloyDB cluster\n",
    "df.to_sql('products', con=f'postgresql://{cluster_ip_address}', if_exists='replace', index=False)\n",
    "\n",
    "# Retrieve data from the 'products' table\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM products\")\n",
    "results = cur.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "print(results[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48fb98e-4e24-489c-a5ce-53effdfad43d",
   "metadata": {},
   "source": [
    "### Task 3. Generate Vector Embeddings using a Text Embedding Model\n",
    "\n",
    "In this section, let's preprocess product descriptions, generate vector embeddings for them, and store the embeddings along with other relevant data in a PostgreSQL database table for downstream analysis or applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206df60-0427-4a9f-94fa-58b88b89caa3",
   "metadata": {},
   "source": [
    "Run the following code snippet to import the RecursiveTextSplitter class from the LangChain library, which is used for splitting text into smaller chunks. Iterate through each row in the DataFrame df and extract the **product ID** and **description** from each row.\n",
    "\n",
    "Then, we will split each description into smaller chunks and will create a dictionary for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc77243d-4987-480b-bbe8-f9355384da40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Set up the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\".\", \"\\n\"],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# Define the maximum number of documents to process\n",
    "max_documents = 50  # Reduced limit to further control API usage\n",
    "documents = []\n",
    "\n",
    "# Create Document objects with product_id as metadata\n",
    "for index, row in df.iterrows():\n",
    "    product_id = row[\"product_id\"]\n",
    "    desc = row[\"description\"]\n",
    "    documents.append(Document(page_content=desc, metadata={\"product_id\": product_id}))\n",
    "\n",
    "# Use the text splitter on a subset of documents (e.g., 40-50)\n",
    "chunked = []\n",
    "docs = text_splitter.split_documents(documents[40:max_documents])\n",
    "\n",
    "# Collect split content along with product_id\n",
    "for doc in docs:\n",
    "    chunked.append({\"product_id\": doc.metadata[\"product_id\"], \"content\": doc.page_content})\n",
    "\n",
    "print(len(chunked))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd70f71-5e74-4088-8e14-cba165dc4e9e",
   "metadata": {},
   "source": [
    "Run the following code snippet to process product descriptions from a dataset by splitting them into smaller chunks, sending them to Vertex AI for embedding generation, and storing the retrieved embeddings back into the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176b717f-3183-459f-bef9-ef0262cbfd6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8a6d71be41e01b284294ec488508b414</td>\n",
       "      <td>All of our productsWalmartply with internation...</td>\n",
       "      <td>[-0.0019801377784460783, -0.037444762885570526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8a6d71be41e01b284294ec488508b414</td>\n",
       "      <td>. Holds Up to 6 Decks Fun for the whole family...</td>\n",
       "      <td>[0.008327648043632507, -0.03802461177110672, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9648838f5badebb9fc0b07f89cc29394</td>\n",
       "      <td>Better circulate water through your pool with ...</td>\n",
       "      <td>[-0.045468609780073166, -0.0008376826299354434...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9648838f5badebb9fc0b07f89cc29394</td>\n",
       "      <td>.25-inch fitting (11070), 2 strainer grids (11...</td>\n",
       "      <td>[-0.020975708961486816, 0.010413266718387604, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9648838f5badebb9fc0b07f89cc29394</td>\n",
       "      <td>. Circulate water through your pool with the h...</td>\n",
       "      <td>[-0.04218039661645889, -0.014087582007050514, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id  \\\n",
       "0  8a6d71be41e01b284294ec488508b414   \n",
       "1  8a6d71be41e01b284294ec488508b414   \n",
       "2  9648838f5badebb9fc0b07f89cc29394   \n",
       "3  9648838f5badebb9fc0b07f89cc29394   \n",
       "4  9648838f5badebb9fc0b07f89cc29394   \n",
       "\n",
       "                                             content  \\\n",
       "0  All of our productsWalmartply with internation...   \n",
       "1  . Holds Up to 6 Decks Fun for the whole family...   \n",
       "2  Better circulate water through your pool with ...   \n",
       "3  .25-inch fitting (11070), 2 strainer grids (11...   \n",
       "4  . Circulate water through your pool with the h...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.0019801377784460783, -0.037444762885570526...  \n",
       "1  [0.008327648043632507, -0.03802461177110672, -...  \n",
       "2  [-0.045468609780073166, -0.0008376826299354434...  \n",
       "3  [-0.020975708961486816, 0.010413266718387604, ...  \n",
       "4  [-0.04218039661645889, -0.014087582007050514, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from google.cloud import aiplatform\n",
    "import time\n",
    "\n",
    "embeddings_service = VertexAIEmbeddings(model_name=\"textembedding-gecko\")\n",
    "\n",
    "# Helper function to retry failed API requests with exponential backoff.\n",
    "def retry_with_backoff(func, *args, retry_delay=10, backoff_factor=2.5, **kwargs):  # Increased delay and backoff factor\n",
    "    max_attempts = 10\n",
    "    retries = 0\n",
    "    for i in range(max_attempts):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"error: {e}\")\n",
    "            retries += 1\n",
    "            wait = retry_delay * (backoff_factor**retries)\n",
    "            print(f\"Retry after waiting for {wait} seconds...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "# Reduced batch size for API calls to manage quota limits\n",
    "batch_size = 3\n",
    "for i in range(0, len(chunked), batch_size):\n",
    "    request = [x[\"content\"] for x in chunked[i : i + batch_size]]\n",
    "    response = retry_with_backoff(embeddings_service.embed_documents, request)\n",
    "    # Store the retrieved vector embeddings for each chunk back.\n",
    "    for x, e in zip(chunked[i : i + batch_size], response):\n",
    "        x[\"embedding\"] = e\n",
    "\n",
    "# Store the generated embeddings in a pandas dataframe.\n",
    "product_embeddings = pd.DataFrame(chunked)\n",
    "product_embeddings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0225006-6a77-4fb0-9169-92a636a89d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!PROJECT_ID=$(gcloud config get-value project) && \\\n",
    "PROJECT_NUMBER=$(gcloud projects list --filter=\"name=$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\") && \\\n",
    "gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "--member=\"serviceAccount:service-$PROJECT_NUMBER@gcp-sa-alloydb.iam.gserviceaccount.com\" \\\n",
    "--role=\"roles/aiplatform.user\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c6b0e-0742-4595-a126-885cc43eed18",
   "metadata": {},
   "source": [
    "Back in the **AlloyDB service page**, click on the cluster named `cymbal-alloy-cluster`, then select **AlloyDB Studio** from the left-hand side menu, enter the following values to sign in, and click on **AUTHENTICATE**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85aff8e-73f5-450d-9cff-e6824c71bae3",
   "metadata": {},
   "source": [
    "Enter the following command in the editor to grant the postgres user permission to execute the `embedding` function, install the `google_ml_integration` extension, and generate an embedding for the provided text using the `textembedding-gecko` model. Then, click on Run button at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713015a5-3627-41fc-9556-4e38c8a308dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRANT EXECUTE ON FUNCTION embedding TO postgres;\n",
    "\n",
    "CREATE EXTENSION IF NOT EXISTS google_ml_integration CASCADE;\n",
    "\n",
    "SELECT embedding('textembedding-gecko', 'AlloyDB is a managed, cloud-hosted SQL database service.');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da87cdb3-efaf-43ea-96a1-b655c947f4ac",
   "metadata": {},
   "source": [
    "Once the embeddings are successfully generated, click the Clear button at the top to clear the contents of the editor. Then, run the following query in the editor to prepare the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4aa124-0f32-4c76-8b57-048727ca0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE EXTENSION IF NOT EXISTS vector;\n",
    "\n",
    "DROP TABLE IF EXISTS product_embeddings;\n",
    "\n",
    "CREATE TABLE product_embeddings(\n",
    "        product_id VARCHAR(1024) NOT NULL PRIMARY KEY,\n",
    "        content TEXT,\n",
    "        embedding vector(768)\n",
    "    );\n",
    "\n",
    "\n",
    "insert into product_embeddings(product_id, content, embedding)\n",
    "SELECT\n",
    "  product_id,\n",
    "  description as content,\n",
    "  embedding('textembedding-gecko', description) as embedding\n",
    "from products\n",
    "where product_id not in (select product_id from product_embeddings)\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd649e5-79d9-47e8-a3d6-6d0304390845",
   "metadata": {},
   "source": [
    "### Task 4. Create Indexes for faster Similarity Search\n",
    "\n",
    "Vector indexes can significantly speed up similarity search operations and avoid the brute-force exact nearest neighbor search that is used by default.\n",
    "\n",
    "**Pgvector** comes with two types of indexes: `hnsw` and `ivfflat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d370bc9-fe61-411e-a5d9-a9cd1e679cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create an HNSW index on the `product_embeddings` table\n",
    "CREATE INDEX ON product_embeddings\n",
    "USING hnsw(embedding vector_cosine_ops)\n",
    "WITH (m = 24, ef_construction = 100);\n",
    "\n",
    "-- Create an IVFFLAT index on the `product_embeddings` table\n",
    "CREATE INDEX ON product_embeddings\n",
    "USING ivfflat(embedding vector_cosine_ops)\n",
    "WITH (lists = 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc47c30-a0cf-4b4a-9250-7539bb6a8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- conduct similarity search\n",
    "with e as (\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    product_embeddings\n",
    "ORDER BY\n",
    "    embedding <-> CAST(embedding('textembedding-gecko','Playing card games') AS vector(768)) asc\n",
    "LIMIT\n",
    "    5\n",
    ")\n",
    "select\n",
    "*\n",
    "from products\n",
    "where product_id in (select e.product_id from e);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64df70-7102-4192-915b-bd1573cc0b44",
   "metadata": {},
   "source": [
    "### Task 5. LLMs and LangChain\n",
    "\n",
    "**Use case 1: Building an AI-curated contextual hybrid search**\n",
    "\n",
    "Combine natural language query text with regular relational filters to create a powerful hybrid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d7af7c-ab3e-407c-b23d-033f19f4a219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please fill in these values.\n",
    "user_query = \"Do you have a toy set that teaches numbers and letters to kids?\"  # @param {type:\"string\"}\n",
    "min_price = 20  # @param {type:\"integer\"}\n",
    "max_price = 100  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703fd687-7afd-4f56-a658-685be3516589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qe = embeddings_service.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d9c05-73d8-4690-909c-eeea3f6806fc",
   "metadata": {},
   "source": [
    "Use pgvector to find similar products. The pgvector similarity search operators provide powerful semantics to combine the vector search operation with regular query filters in a single SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c59d4a-4fc9-4ccd-862f-eca287328e91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   product_name  list_price  \\\n",
      "0               12\"-20\" Schwinn Training Wheels       28.17   \n",
      "1  Slip N Slide Triple Racer with Slide Boogies       37.21   \n",
      "\n",
      "                                         description  \n",
      "0  Turn any small bicycle into an instrument for ...  \n",
      "1  Triple Racer Slip and Slide with Boogie Boards...  \n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import pandas as pd\n",
    "\n",
    "def main(user_query, min_price, max_price):\n",
    "    try:\n",
    "        # AlloyDB cluster connection details (replace with your actual values)\n",
    "        cluster_ip_address = \"10.103.0.2\"\n",
    "        database_user = \"postgres\"\n",
    "        database_password = \"postgres\"\n",
    "\n",
    "        # Connect to AlloyDB cluster\n",
    "        conn = psycopg2.connect(\n",
    "            host=cluster_ip_address,\n",
    "            user=database_user,\n",
    "            password=database_password\n",
    "        )\n",
    "\n",
    "        # Register the vector type\n",
    "        register_vector(conn)\n",
    "\n",
    "        # Get the query embedding\n",
    "        qe = embeddings_service.embed_query(user_query)\n",
    "\n",
    "        # Check if qe is valid\n",
    "        if not qe:\n",
    "            print(\"Error: The query embedding is empty.\")\n",
    "            return\n",
    "\n",
    "        # Perform the similarity search and filtering\n",
    "        cur = conn.cursor()\n",
    "        similarity_threshold = 0.5  # Increased threshold for broader matching\n",
    "        num_matches = 50\n",
    "\n",
    "        # Modify the SQL query for indexed similarity search\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            WITH vector_matches AS (\n",
    "                SELECT product_id, embedding <=> %s::vector AS distance\n",
    "                FROM product_embeddings\n",
    "                WHERE embedding <=> %s::vector < %s\n",
    "                ORDER BY distance ASC\n",
    "                LIMIT %s\n",
    "            )\n",
    "            SELECT product_name, list_price, description\n",
    "            FROM products\n",
    "            WHERE product_id IN (SELECT product_id FROM vector_matches)\n",
    "            AND list_price >= %s AND list_price <= %s\n",
    "            \"\"\",\n",
    "            (qe, qe, similarity_threshold, num_matches, min_price, max_price)\n",
    "        )\n",
    "        results = cur.fetchall()\n",
    "\n",
    "        # Check if any results are retrieved\n",
    "        if not results:\n",
    "            print(\"No results found. Try adjusting the similarity threshold or checking the data.\")\n",
    "            return\n",
    "\n",
    "        # Process the results\n",
    "        matches = []\n",
    "        for r in results:\n",
    "            try:\n",
    "                list_price = round(float(r[1]), 2)  # Attempt conversion and rounding\n",
    "            except ValueError:\n",
    "                list_price = r[1]  # Use original value if conversion fails\n",
    "            matches.append({\n",
    "                \"product_name\": r[0],\n",
    "                \"list_price\": list_price,\n",
    "                \"description\": r[2]\n",
    "            })\n",
    "\n",
    "        # Display the results\n",
    "        matches_df = pd.DataFrame(matches)\n",
    "        print(matches_df.head(5))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during database operations: {e}\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Call the main function\n",
    "main(\"Do you have a toy set that teaches numbers and letters to kids?\", 25, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41ff156-8ee4-4490-bf9d-78bbf6bb6608",
   "metadata": {},
   "source": [
    "After finding the similar products and their descriptions using pgvector, the next step is to use them for generating a prompt input for the LLM model. Since individual product descriptions can be very long, they may not fit within the specified input payload limit for an LLM model. The `MapReduceChain` from the `LangChain` framework is used to generate and combine short summaries of similarly matched products. The combined summaries are then used to build a high-quality prompt for an input to the LLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb59e76-47e4-42b5-bf11-7a772af76c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. **Name:** Number Puzzle\n",
       "2. **Price:** $20\n",
       "3. **Features:**\n",
       "    - Interactive\n",
       "    - Promotes number learning\n",
       "\n",
       "Although the Alphabet Learning Toy also teaches letters, the Number Puzzle is a better fit for the question as it specifically focuses on numbers and is more interactive, making it a more engaging learning experience for children. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Mock matches data\n",
    "matches = [\n",
    "    {\"product_name\": \"Alphabet Learning Toy\", \"price\": 30, \"features\": \"Teaches letters and numbers.\"},\n",
    "    {\"product_name\": \"Number Puzzle\", \"price\": 20, \"features\": \"Interactive puzzle for number learning.\"},\n",
    "]\n",
    "\n",
    "# LangChain setup\n",
    "llm = VertexAI(model_name=\"gemini-pro\")\n",
    "\n",
    "map_prompt_template = \"\"\"\n",
    "            You will be given a detailed description of a toy product.\n",
    "            This description is enclosed in triple backticks (```).\n",
    "            Using this description only, extract the name of the toy,\n",
    "            the price of the toy and its features.\n",
    "\n",
    "            ```{text}```\n",
    "            SUMMARY:\n",
    "            \"\"\"\n",
    "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "combine_prompt_template = \"\"\"\n",
    "                You will be given a detailed description of different toy products\n",
    "                enclosed in triple backticks (```) and a question enclosed in\n",
    "                double backticks(``).\n",
    "                Select one toy that is most relevant to answer the question.\n",
    "                Using that selected toy description, answer the following\n",
    "                question in as much detail as possible.\n",
    "                You should only use the information in the description.\n",
    "                Your answer should include the name of the toy, the price of the toy\n",
    "                and its features. Your answer should be less than 200 words.\n",
    "                Your answer should be in Markdown in a numbered list format.\n",
    "\n",
    "                Description:\n",
    "                ```{text}```\n",
    "\n",
    "                Question:\n",
    "                ``{user_query}``\n",
    "\n",
    "                Answer:\n",
    "                \"\"\"\n",
    "combine_prompt = PromptTemplate(\n",
    "    template=combine_prompt_template, input_variables=[\"text\", \"user_query\"]\n",
    ")\n",
    "\n",
    "# Convert matches to LangChain documents\n",
    "docs = [\n",
    "    Document(page_content=f\"Name: {match['product_name']}, Price: {match['price']}, Features: {match['features']}\")\n",
    "    for match in matches\n",
    "]\n",
    "\n",
    "# Load and invoke the chain\n",
    "chain = load_summarize_chain(\n",
    "    llm, chain_type=\"map_reduce\", map_prompt=map_prompt, combine_prompt=combine_prompt\n",
    ")\n",
    "\n",
    "# User query\n",
    "user_query = \"Do you have a toy set that teaches numbers and letters to kids?\"\n",
    "\n",
    "# Invoke the chain\n",
    "output = chain.invoke({\n",
    "    \"input_documents\": docs,\n",
    "    \"user_query\": user_query,\n",
    "})\n",
    "\n",
    "# Extract and display the output\n",
    "answer = output.get('output_text', ' ')\n",
    "display(Markdown(answer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9316ba-52dc-4f3a-a368-b10a353ecd5f",
   "metadata": {},
   "source": [
    "**Use case 2: Adding AI-powered creative content generation**\n",
    "\n",
    "Use knowledge from the existing dataset to generate new AI-powered content from an initial prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fa7e22f-7de9-483a-ba0e-45e9818a1025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please fill in these values.\n",
    "creative_prompt = \"A bicycle with brand name 'Roadstar bike' for kids that comes with training wheels and helmet.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a822248-2c4e-4d0b-a135-5d76682d588e",
   "metadata": {},
   "source": [
    "Leverage the pgvector similarity search operator to find an existing product description that closely matches the new product specified in the initial prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30861b68-4fb1-4a9d-b882-c14b20d9c371",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches found: ['Turn any small bicycle into an instrument for learning to ride with the Schwinn 12\"-20\" Training Wheels. They feature a slotted design to fit 12\" to 20\" bikes. The training wheels are easy to assemble, install and remove, so that when your little one is able to ride without assistance, you can take them off. These bicycle training wheels include steel brackets and rubber tires that can stand up to heavy use. Training Wheels, Fits 12 inches - 20 inches bicycles. Est. 1895. Durable Construction: Steel brackets stand up to heavy use. Customizable: Two sets of wheel decals included. Features: Fits Most Childrens Bicycles: Intended for 12 inch - 20 inch bicycles. Steel Brackets: Offer increased durability. Includes two sets of wheel decals: Learn how to ride in style - see images below. Easy to Adjust: Slotted design for size adjustment. Includes: One pair of training wheels, four decals, installation instructions, and all mounting hardware. Tools required: Adjustable wrench. www.schwinnbikes.com. Follow ride Schwinn on: Twitter. Facebook. Made in China. Training Wheels,Fits 12 inches - 20 inches bicycles. Est. 1895. Durable Construction: Steel brackets stand up to heavy use. Customizable: Two sets of wheel decals included. Features: Fits Most Childrens Bicycles: Intended for 12 inch - 20 inch bicycles. Steel Brackets: Offer increased durability. Includes two sets of wheel decals: Learn how to ride in style - see images below. Easy to Adjust: Slotted design for size adjustment. Includes: One pair of training wheels, four decals, installation instructions, and all mounting hardware. Tools required: Adjustable wrench. www.schwinnbikes.com. Follow ride Schwinn on: Twitter. Facebook. Made in China.']\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # AlloyDB cluster connection details\n",
    "        cluster_ip_address = \"10.103.0.2\"\n",
    "        database_user = \"postgres\"\n",
    "        database_password = \"postgres\"\n",
    "\n",
    "        # Connect to AlloyDB cluster\n",
    "        conn = psycopg2.connect(\n",
    "            host=cluster_ip_address,\n",
    "            user=database_user,\n",
    "            password=database_password\n",
    "        )\n",
    "\n",
    "        # Register the vector type\n",
    "        register_vector(conn)\n",
    "\n",
    "        # Get the query embedding\n",
    "        qe = embeddings_service.embed_query(creative_prompt)\n",
    "\n",
    "        # Check if qe is a valid embedding\n",
    "        if not qe:\n",
    "            print(\"Error: The query embedding is empty.\")\n",
    "            return\n",
    "\n",
    "        # Set similarity threshold\n",
    "        similarity_threshold = 0.5\n",
    "        matches = []\n",
    "\n",
    "        # Perform the similarity search and filtering\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            WITH vector_matches AS (\n",
    "                SELECT product_id, embedding <=> %s::vector AS distance\n",
    "                FROM product_embeddings\n",
    "                WHERE embedding <=> %s::vector < %s\n",
    "                ORDER BY distance ASC\n",
    "                LIMIT 1\n",
    "            )\n",
    "            SELECT description FROM products\n",
    "            WHERE product_id IN (SELECT product_id FROM vector_matches)\n",
    "            \"\"\",\n",
    "            (qe, qe, similarity_threshold)\n",
    "        )\n",
    "\n",
    "        results = cur.fetchall()\n",
    "\n",
    "        # Process the results\n",
    "        for r in results:\n",
    "            matches.append(r[0])\n",
    "\n",
    "        if not matches:\n",
    "            print(\"No matches found.\")\n",
    "        else:\n",
    "            print(\"Matches found:\", matches)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during database operations: {e}\")\n",
    "    finally:\n",
    "        # Close the connection if it was established\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Call the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872af60e-453f-4c9c-bf32-e8d897e5acda",
   "metadata": {},
   "source": [
    "Use the existing matched product description as the prompt context to generate new creative output from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55e3b187-da9e-4ca5-a8b1-a54ef580995a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## A 2-in-1 Transforming Playset: Indoor Castle & Outdoor Adventure\n",
       "\n",
       "This innovative toy seamlessly transforms between a majestic indoor castle and a thrilling outdoor adventure scene, offering endless possibilities for imaginative play. \n",
       "\n",
       "**Castle Mode:**\n",
       "\n",
       "*   **Sturdy Structure:** The castle features a durable, interlocking construction with towers, turrets, and a drawbridge, providing a secure and captivating environment for indoor adventures.\n",
       "*   **Interactive Features:** A hidden treasure chest, secret passageways, and a working portcullis ignite children's imaginations as they embark on quests, defend the castle, or role-play as their favorite characters.\n",
       "*   **Cozy Play Space:** The castle's interior transforms into a cozy play space with soft, cushioned walls and a plush rug, perfect for reading, storytelling, or quiet playtime.\n",
       "\n",
       "**Adventure Mode:**\n",
       "\n",
       "*   **Transforming Landscape:** With a few simple adjustments, the castle unfolds into a sprawling outdoor scene, complete with a winding path, a hidden cave, and a towering tree.\n",
       "*   **Nature Exploration:** The set includes realistic accessories like a campfire, a telescope, and binoculars, encouraging children to explore, observe, and connect with nature.\n",
       "*   **Physical Activity:** The expansive play area provides ample space for running, jumping, and engaging in active play, promoting healthy development and physical fitness.\n",
       "\n",
       "**Additional Features:**\n",
       "\n",
       "*   **Durable and Weather-Resistant:** Made from high-quality materials, the toy can withstand both indoor and outdoor use, ensuring long-lasting enjoyment.\n",
       "*   **Easy to Clean:** The smooth surfaces and removable fabric components allow for quick and effortless cleaning.\n",
       "*   **Suitable for Multiple Ages:** The versatility of the toy allows children of different ages to enjoy it together, fostering sibling bonding and social interaction.\n",
       "*   **Imaginative Play:** The 2-in-1 design encourages creativity, problem-solving, and storytelling, fostering a love for imaginative play that extends beyond the toy itself. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "# Define the template\n",
    "template = \"\"\"\n",
    "            You are given descriptions about some similar kind of toys in the context.\n",
    "            This context is enclosed in triple backticks (```).\n",
    "            Combine these descriptions and adapt them to match the specifications in\n",
    "            the initial prompt. All the information from the initial prompt must\n",
    "            be included. You are allowed to be as creative as possible,\n",
    "            and describe the new toy in as much detail. Your answer should be\n",
    "            in markdown in lists and less than 200 words.\n",
    "\n",
    "            Context:\n",
    "            ```{context}```\n",
    "\n",
    "            Initial Prompt:\n",
    "            {creative_prompt}\n",
    "\n",
    "            Answer:\n",
    "        \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template, input_variables=[\"context\", \"creative_prompt\"]\n",
    ")\n",
    "\n",
    "# Define the LLM\n",
    "llm = VertexAI(model_name=\"gemini-pro\", temperature=0.7)\n",
    "\n",
    "# Example `matches` list\n",
    "matches = [\n",
    "    {\"description\": \"This is a toy description 1.\"},\n",
    "    {\"description\": \"This is a toy description 2.\"},\n",
    "    {},  # Missing `description`\n",
    "    \"Invalid item\"  # Not a dictionary\n",
    "]\n",
    "\n",
    "# Construct the context by extracting valid descriptions\n",
    "context = \"\\n\".join(\n",
    "    item[\"description\"] for item in matches if isinstance(item, dict) and \"description\" in item\n",
    ")\n",
    "\n",
    "# Define the creative prompt\n",
    "creative_prompt = \"Describe a toy that is suitable for both indoor and outdoor play.\"\n",
    "\n",
    "# Use RunnableSequence for chaining\n",
    "llm_chain = RunnableSequence(prompt | llm)\n",
    "\n",
    "# Invoke the chain\n",
    "answer = llm_chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"creative_prompt\": creative_prompt,\n",
    "})\n",
    "\n",
    "# Display the answer in Markdown format\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
